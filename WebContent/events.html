<html>

<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Events</title>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://sketch2.csail.mit.edu/SynthesisCourse/library.js"></script>
<script type="text/javascript" src="overrides.js"></script>
<link href="style.css" rel="stylesheet" type="text/css">
</head>

<body onresize="resizing()">


<div class="header">
<h1 style="color: rgb(165, 42, 42);">Understanding the World Through Code</h1>
<h2 style="color: 'black';">Funded through the NSF Expeditions in Computing Program</h2>
<div class="logos">
<img title='mit' src='images/mit.png' height='100%' />
<img title='ut' src='images/ut.png' height='100%'/>
<img title='caltech' src='images/caltech.png' height='100%'/>
<img title='rice' src='images/rice.png' height='100%'/>
<img title='penn' src='images/penn.png' height='100%'/>
<img title='stanford' src='images/stanford.png' height='100%'/>
</div>
<div id='navicon.div' class='navicon'>
<img id = 'navicon' src="images/burger.rest.png"
onmouseenter="iconEnter(this, 'burger')"
onmouseleave="iconLeave(this, 'burger')"
onclick = 'toggleNav()'
title="Navigation" width="34pt"></img>
</div>
</div>


<div id="navigator" class="sidenav">
<a href="#about">Lecture 1</a>
<a href="#services">Lecture 2</a>
<a href="#clients">Lecture 3</a>
<a href="#contact">Lecture 4</a>
</div>
<script type="text/javascript">
loadNavBar();
</script>

<div class="content">

<h1>Events</h1>
You can <a href="https://lists.csail.mit.edu/mailman/listinfo/neurosym-public"> subscribe to our public mailing list</a>
to receive announcements about upcoming events.
	
<div class="event">
<span class="event_title" id="NeurosymWebinar">
7/2021: Neurosym webinar series
</span>
Hima Lakkaraju &mdash; Assistant Professor at Harvard University &mdash; will be talking about interpretable machine learning. 	

<div class="talk_box">
<h1>Towards Reliable and Robust Model Explanations</h1>

As machine learning black boxes are increasingly being deployed in domains such as healthcare and criminal justice, there is growing emphasis on building tools and techniques for explaining these black boxes in an interpretable manner. Such explanations are being leveraged by domain experts to diagnose systematic errors and underlying biases of black boxes. In this talk, I will present some of our recent research that sheds light on the vulnerabilities of popular post hoc explanation techniques such as LIME and SHAP, and also introduce novel methods to address some of these vulnerabilities. More specifically, I will first demonstrate that these methods are brittle, unstable, and are vulnerable to a variety of adversarial attacks. Then, I will discuss two solutions to address some of the aforementioned vulnerabilities–(i) a Bayesian framework that captures the uncertainty associated with post hoc explanations and in turn allows us to generate explanations with user specified levels of confidence, and (ii) a framework based on adversarial training that is designed to make post hoc explanations more stable and robust to shifts in the underlying data; I will conclude the talk by discussing our recent theoretical results which shed light on the equivalence and robustness of state-of-the-art explanation methods.
<p/>
<B>Bio:</B> Hima Lakkaraju is an Assistant Professor at Harvard University focusing on explainability, fairness, and robustness of machine learning models.  She has also been working with various domain experts in criminal justice and healthcare to understand the real world implications of explainable and fair ML. Hima has recently been named one of the 35 innovators under 35 by MIT Tech Review, and has received best paper awards at SIAM International Conference on Data Mining (SDM) and INFORMS. She has given invited workshop talks at ICML, NeurIPS, AAAI, and CVPR, and her research has also been covered by various popular media outlets including the New York Times, MIT Tech Review, TIME, and Forbes. For more information, please visit: https://himalakkaraju.github.io/  </br>

<div class="whenwhere">
<B>When:</B> Tuesday Jul 27, 2021 04:00 PM Eastern Time (US and Canada)<BR>
	<B>Where:</B> <a href='https://upenn.zoom.us/j/99059584615?pwd=TDRqbFpCTDVpeHJSbnVYeTFqWEdpZz09'>Zoom</a>	
</div>
	
</div>
			
</div

<div class="event">
<span class="event_title" id="NeurosymWebinar">
4/2021: Neurosym webinar series
</span>
Percy Liang &mdash; Associate Professor of Computer Science at Stanford University &mdash; will be talking about machine learning for program repair. 			
	  
<div class="talk_box">
<h1>Learning to Fix Programs</h1>

A huge amount of time is spent by programmers fixing broken code.  Our goal is to train neural models that can do this automatically.  I will first present DrRepair, a system that learns to edit programs based on error messages.  We leverage a large number of valid programs by artificially perturbing (and thus breaking) them.  DrRepair obtains strong results on two tasks: fixing errors made by students and pseudocode-to-code translation.  We then present a new framework, Break-It-Fix-It (BIFI), which additionally leverages unlabeled broken code to learn a model that perturbs code to generate more realistic broken code.  We show that this results in further improvements over DrRepair.  Taken together, our work suggests that one can learn a lot just from unlabeled programs and a compiler and no further manual annotations.<p/>
<p/>
<B>Bio:</B> Percy Liang is an Associate Professor of Computer Science at Stanford University (B.S. from MIT, 2004; Ph.D. from UC Berkeley, 2011).  His research spans many topics in machine learning and natural language processing, including robustness, interpretability, semantics, and reasoning.  He is also a strong proponent of reproducibility through the creation of CodaLab Worksheets.  His awards include the Presidential Early Career Award for Scientists and Engineers (2019), IJCAI Computers and Thought Award (2016), an NSF CAREER Award (2016), a Sloan Research Fellowship (2015), a Microsoft Research Faculty Fellowship (2014), and multiple paper awards at ACL, EMNLP, ICML, and COLT.  </br>

<div class="whenwhere">
<B>When:</B> Tuesday, April 27 2021, 4-5pm EST <BR>
<B>Watch:</B> <a href='https://youtu.be/dEUpGzatEt8'>Recorded Talk</a>	
</div>

</div>
		
</div


<div class="event">
<span class="event_title" id="NeurosymWebinar">
3/2021: Neurosym webinar series
</span>
Jacob Andreas &mdash; X Consortium Assistant Professor at MIT in EECS and CSAIL &mdash; will be talking about symbolic representation and reasoning in DNNs. 
			
	  
<div class="talk_box">
<h1>Implicit Symbolic Representation and Reasoning in Deep Neural Networks</h1>
		
Standard neural network architectures can *in principle* implement symbol processing operations like logical deduction and simulation of complex automata. But do current neural models, trained on standard tasks like image recognition and language understanding, learn to perform symbol manipulation *in practice*? I'll survey two recent findings about implicit symbolic behavior in deep networks. First, I will describe a procedure for automatically labeling neurons with compositional logical descriptions of their behavior. These descriptions surface interpretable learned abstractions in models for vision and language, reveal implicit logical "definitions" of visual and linguistic categories, and enable the design of simple adversarial attacks that exploit errors in definitions. Second, I'll describe ongoing work showing that neural models for language generation perform implicit simulation of entities and relations described by text. Representations in these language models can be (linearly) translated into logical representations of world state, and can be directly edited to produce predictable changes in generated output. Together, these results suggest that highly structured representations and behaviors can emerge even in relatively unstructured models trained on natural tasks. Symbolic models of computation can play a key role in helping us understand these models.
<p/>
<B>Bio:</B> Jacob Andreas is the X Consortium Assistant Professor at MIT in EECS and CSAIL. He did his PhD work at Berkeley, where he was a member of the Berkeley NLP Group and the Berkeley AI Research Lab. He has also spent time with the Cambridge NLIP Group, and the Center for Computational Learning Systems and NLP Group at Columbia. </br>
	
<div class="whenwhere">
<B>When:</B> Tuesday, March 23 2021, 4-5pm EST <BR>
<B>Watch:</B> <a href='https://youtu.be/MwhKvQ7wrVk'>Recorded Talk</a>	
</div>

</div>
		
</div

	
<div class="event">
<span class="event_title" id="NeurosymWebinar">
2/2021: Neurosym webinar series
</span>
Mayur Naik &mdash; Professor of Computer and Information Science at the University of Pennsylvania &mdash; will be talking about differentiable reasoning.
			
	  
<div class="talk_box">
<h1>Scallop: End-to-end Differentiable Reasoning at Scale</h1>
		
Approaches to systematically combine symbolic reasoning with deep learning have demonstrated remarkable promise in terms of accuracy and generalizability.  However, the complexity of exact probabilistic reasoning renders these methods inefficient for real-world, data-intensive machine learning applications.  I will present Scallop, a scalable differentiable probabilistic Datalog engine equipped with a top-k approximate inference algorithm.  The algorithm significantly reduces the amount of computation needed for inference and learning tasks without affecting their principal outcomes.  To evaluate Scallop, we have crafted a challenging dataset, VQAR, comprising 4 million Visual Question Answering (VQA) instances that necessitate reasoning about real-world images with external common-sense knowledge.  Scallop not only scales to these instances but also outperforms state-of-the-art neural-based approaches by 12.44%.

<p/>
<B>Bio:</B> Mayur Naik is a Professor of Computer and Information Science at the University of Pennsylvania.  His research spans the area of programming languages, with a current emphasis on developing scalable techniques to reason about programs by combining machine learning and formal methods.  He is also interested in foundations and applications of neuro-symbolic approaches that synergistically combine deep learning and symbolic reasoning.  He received a Ph.D. in Computer Science from Stanford University in 2008.  Previously, he was a researcher at Intel Labs, Berkeley from 2008 to 2011, and an assistant professor in the College of Computing at Georgia Tech from 2011 to 2016. </br>
	
<div class="whenwhere">
<B>When:</B> Tuesday, February 23 2021, 4-5pm EST <BR>
<B>Watch:</B> <a href='https://youtu.be/JUqMP4Mb5ng'>Recorded Talk</a>	
</div>

</div>
		
</div>
	
	
<div class="event">
<span class="event_title" id="NeurosymWebinar">
1/2021: Neurosym webinar series
</span>
Jiajun Wu &mdash; Assistant Professor of Computer Science at Stanford University &mdash; will be talking about some of his work on neurosymbolic approaches to computer vision.
			
	  
<div class="talk_box">
<h1>Understanding the Visual World Through Code</h1>
		
Much of our visual world is highly regular: objects are often symmetric and have repetitive parts; indoor scenes such as corridors often consist of objects organized in a repetitive layout. How can we infer and represent such regular structures from raw visual data, and later exploit them for better scene recognition, synthesis, and editing? In this talk, I will present our recent work on developing neuro-symbolic methods for scene understanding. Here, symbolic programs and neural nets play complementary roles: symbolic programs are more data-efficient to train and generalize better to new scenarios, as they robustly capture high-level structure; deep nets effectively extract complex, low-level patterns from cluttered visual data. I will demonstrate the power of such hybrid models in three different domains: 2D image editing, 3D shape modeling, and human motion understanding.

<p/>
<B>Bio:</B> Jiajun Wu is an Assistant Professor of Computer Science at Stanford University, working on computer vision, machine learning, and computational cognitive science. Before joining Stanford, he was a Visiting Faculty Researcher at Google Research. He received his PhD in Electrical Engineering and Computer Science at Massachusetts Institute of Technology. Wu's research has been recognized through the ACM Doctoral Dissertation Award Honorable Mention, the AAAI/ACM SIGAI Doctoral Dissertation Award, the MIT George M. Sprowls PhD Thesis Award in Artificial Intelligence and Decision-Making, the 2020 Samsung AI Researcher of the Year, the IROS Best Paper Award on Cognitive Robotics, and fellowships from Facebook, Nvidia, Samsung, and Adobe.</br>
	
<div class="whenwhere">
<B>When:</B> Tuesday January 26, 2021, 4-5pm EST <BR>
<B>Watch:</B> <a href='https://youtu.be/1IjVVtJZ9Fc'>Recorded Talk</a>
</div>

</div>
		
</div>


<div class="event">
<span class="event_title" id="NeurosymWebinar">
12/2020: Neurosym webinar series
</span>
Justin Gottschlich &mdash; Principal Scientist and the Director & Founder of Machine Programming Research at Intel Labs &mdash; will be talking about Machine Programming. 
		
  
<div class="talk_box">
<h1>A Glance into Machine Programming @ Intel Labs</h1>
	
As defined by "The Three Pillars of Machine Programming", machine programming (MP) is concerned with the automation of software development. The three pillars partition MP into the following conceptual components: (i) intention, (ii) invention, and (iii) adaptation, with data being a foundational element that is generally necessary for all pillars. While the goal of MP is complete software automation – something that is likely decades away – we believe there are many seminal research opportunities waiting to be explored today across the three pillars. </br>

In this talk, we will provide a glance into the new Pioneering Machine Programming Research effort at Intel Labs and how it has been established around the three pillars across the entire company. We will also discuss Intel Labs’ general charter for MP, as well as a few early research systems that we have built and are using today to improve the quality and rate at which we are developing software (and hardware) in production systems
<p/>
<B>Bio:</B> Justin Gottschlich is a Principal Scientist and the Director & Founder of Machine Programming Research at Intel Labs. He also has an academic appointment as an Adjunct Assistant Professor at the University of Pennsylvania. Justin is the Principal Investigator of the joint Intel/NSF CAPA research center, which focuses on simplifying the software programmability challenge for heterogeneous hardware. He co-founded the ACM SIGPLAN Machine Programming Symposium (previously Machine Learning and Programming Languages) and currently serves as its Steering Committee Chair. He is currently serving on two technical advisory boards: the 2020 NSF Expeditions “Understanding the World Through Code” and a new MP startup fully funded by Intel, which is currently in stealth.</br>

Justin has a deep desire to build bridges with thought leaders across industry and academia to research disruptive technology as a community. Recently, he has been focused on machine programming, which is principally about automating software development. Justin currently has active collaborations with Amazon, Brown University, Georgia Tech, Google AI, Hebrew University, IBM Research, Microsoft Research, MIT, Penn, Stanford, UC-Berkeley, UCLA, and University of Wisconsin. He received his PhD in Computer Engineering from the University of Colorado-Boulder in 2011. Justin has 30+ peer-reviewed publications, 35+ issued patents, with 100+ patents pending.
	
<div class="whenwhere">
<B>When:</B> Tuesday December 1, 4-5PM EST. <BR>
<B>Watch:</B> <a href='https://youtu.be/W2kqtU7WbJ0'>Recorded Talk</a>
</div>

</div>
	
</div>

	
<div class="event">
<span class="event_title" id="NeurosymWebinar">
10/2020: Neurosym webinar series
		 </span>
Abhinav Verma &mdash; PhD student at UT Austin &mdash; will talk about his recent work on reinforcement learning algorithms. 
		
  
<div class="talk_box">
<h1>Programmatic Reinforcement Learning</h1>
	
We study reinforcement learning algorithms that generate policies that can be represented in expressive high-level Domain Specific Languages (DSL). This work aims to simultaneously address four fundamental drawbacks of Deep Reinforcement Learning (Deep-RL), where the policy is represented by a neural network; interpretability, verifiability, reliability and domain awareness. We formalize a new learning paradigm and provide empirical and theoretical evidence to show that we can generate policies in expressive DSLs that do not suffer from the above shortcomings of Deep-RL. To overcome the challenges of policy search in non-differentiable program space, we introduce a meta-algorithm that is based on mirror descent, program synthesis, and imitation learning. This approach leverages neurosymbolic learning, using synthesized symbolic programs to regularize Deep-RL and using the gradients available to Deep-RL to improve the quality of synthesized programs. Overall this approach establishes a synergistic relationship between Deep-RL and program synthesis.
	
<p/>
<B>Bio:</B> Abhinav Verma is a PhD student at UT Austin where he is supervised by Swarat Chaudhuri. His research lies at the intersection of machine learning and program synthesis, with a focus on programmatically interpretable learning. He is a recipient of the 2020 JP Morgan AI Research PhD Fellowship.
	
<div class="whenwhere">
<B>When:</B> Tuesday October 27, 4-5PM EST. <BR>
<B>Watch:</B> <a href='https://youtu.be/fl4OELqCFOs'>Recorded Talk</a>
</div>

</div>
	
</div>
	
  
<div class="event">
<span class="event_title" id="kickoff">
10/2020: We are having our official kickoff meeting
 </span>
Some of the talks will be streamed online, see the <a href="kickoff.html">schedule</a> for the recordings. 
</div>


<div class="event">
<span class="event_title" id="NeurosymWebinar">
9/2020: Neurosym webinar series.
 </span>
In the first talk in the series, Kevin Ellis &mdash; research scientist at Common Sense Machines, and soon to be faculty member at 
the Computer Science Department at Cornell &mdash; will talk about his recent work on growing domain specific languages. 
	

<div class="talk_box">
<h1>Growing domain-specific languages alongside neural program synthesizers via wake-sleep program learning</h1>

Two challenges in engineering program synthesis systems are: (1) crafting specialized yet expressive domain specific languages, and (2) designing search algorithms that can tractably explore the space of expressions in this domain specific language. We take a step toward the joint learning of domain specific languages, and the search algorithms that perform synthesis in that language. We propose an algorithm which starts with a relatively minimal domain specific language, and then enriches that language by compressing out common syntactic patterns into a library of reusable domain specific code. In tandem, the system trains a neural network to guide search over expressions in the growing language. From a machine learning perspective, this system implements a wake-sleep algorithm similar to the Helmholtz machine. We apply this algorithm to AI and program synthesis problems, with the goal of understanding how domain specific languages and neural program synthesizers can mutually bootstrap one another.
<p/>
<a href="https://arxiv.org/abs/2006.08381">Related paper</a>

<p/>
<B>Bio:</B> Kevin Ellis is a research scientist at Common Sense Machines, and recently finished a PhD at MIT under Armando Solar-Lezama and Josh Tenenbaum. He works on program synthesis and artificial intelligence. He will be moving to Cornell to start as an assistant professor in the computer science department starting fall 2021.

<div class="whenwhere">
<B>When:</B> Tuesday September 29, 4-5PM EST. <BR>
<B>Watch:</B> <a href='https://youtu.be/D_TSGSvQqpw'>Recorded Talk</a>
</div>

</div>

</div>


<div class="event">
<span class="event_title" id="tapia2020">
7/2020: Meet us at <a href="http://tapiaconference.org/">Tapia 2020</a>.
 </span>

We will be present at <a href="http://tapiaconference.org/supporters/#sponsor-understanding-the-world-through-code">Tapia 2020</a>. If you are attending the (virtual) conference, come talk to us to learn more about the project and opportunities for undergraduate summer research.

</div>


<script>
processDocument();
</script>

<div class="footnotes">

<footnotes>

</footnotes>

</div>
</div>

</body>



</html>
